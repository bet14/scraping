{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4834fc79-0b05-45a2-9cae-0db66040e1ce",
   "metadata": {},
   "source": [
    "# Scraping Thơ Đỗ Phủ trên thivien.net\n",
    "- lấy url của các bài thơ\n",
    "- mở url lấy nội dung thơ (chữ Hán, phiên âm Hán Việt, phiên dịch)\n",
    "*trang block scrap nên phải dùng header "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d964e38-25d1-43c2-a95b-b51e3e0e939a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "import csv\n",
    "import re\n",
    "import pandas \n",
    "import requests\n",
    "\n",
    "from docx import Document\n",
    "\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4195fd93-5a59-40c3-9941-4605e4fecd96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang tải nội dung trang web...\n",
      "Nội dung trang web đã được tải thành công.\n",
      "Phân tích HTML content...\n",
      "Trích xuất các URL chứa từ 'poem' nhưng không lấy từ 'searchpoem'...\n",
      "Các URL chứa từ 'poem' nhưng không lấy từ 'searchpoem' đã được lưu vào D:/Dophu-url-poem.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "user_agents_list = [\n",
    "    'Mozilla/5.0 (iPad; CPU OS 12_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Mobile/15E148',\n",
    "    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.83 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.51 Safari/537.36'\n",
    "]\n",
    "\n",
    "# URL của trang web cần scrap\n",
    "url = \"https://www.thivien.net/%C4%90%E1%BB%97-Ph%E1%BB%A7/author-Se3x2jWTezvoDpkpSU9qjg\"\n",
    "\n",
    "try:\n",
    "    # Tải nội dung của trang web\n",
    "    print(\"Đang tải nội dung trang web...\")\n",
    "    response = requests.get(url, headers={'User-Agent': random.choice(user_agents_list)})\n",
    "    response.raise_for_status()  # Ném ngoại lệ cho các mã trạng thái không tốt\n",
    "    print(\"Nội dung trang web đã được tải thành công.\")\n",
    "\n",
    "    # Phân tích HTML content\n",
    "    print(\"Phân tích HTML content...\")\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Trích xuất các URL từ trang web chứa từ \"poem\" nhưng không lấy từ \"searchpoem\"\n",
    "    print(\"Trích xuất các URL chứa từ 'poem' nhưng không lấy từ 'searchpoem'...\")\n",
    "    urls = [a[\"href\"] for a in soup.find_all(\"a\", href=True) if \"poem\" in a[\"href\"] and \"searchpoem\" not in a[\"href\"] and \"addpoem\" not in a[\"href\"] and \"m-poems\" not in a[\"href\"]]\n",
    "\n",
    "\n",
    "    # Lưu các URL vào tệp CSV\n",
    "    file_path = \"D:/Dophu-url-poem.csv\"\n",
    "    with open(file_path, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow([\"URL\"])\n",
    "\n",
    "        for url in urls:\n",
    "            writer.writerow([url])\n",
    "\n",
    "    print(f\"Các URL chứa từ 'poem' nhưng không lấy từ 'searchpoem' đã được lưu vào {file_path}\")\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(\"Lỗi khi tải URL:\", e)\n",
    "except Exception as e:\n",
    "    print(\"Đã xảy ra lỗi:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d233e495-514b-469d-96df-5dc74eec8088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang tải nội dung trang web: https://www.thivien.net/%C4%90%E1%BB%97-Ph%E1%BB%A7/Thu-h%E1%BB%A9ng-k%E1%BB%B3-1/poem-d-FDjEupVCgpsc1eaacNvg\n",
      "Tiêu đề: Bài thơ: Thu hứng kỳ 1 - 秋興其一 (Đỗ Phủ - 杜甫)\n",
      "Đã thêm dữ liệu mới vào file D:/dophu_poem.docx\n",
      "Đang tải nội dung trang web: https://www.thivien.net/%C4%90%E1%BB%97-Ph%E1%BB%A7/%C4%90%C4%83ng-cao/poem-h3EvqeQvlQUxq2sceUWWYQ\n",
      "Tiêu đề: Bài thơ: Đăng cao - 登高 (Đỗ Phủ - 杜甫)\n",
      "Đã thêm dữ liệu mới vào file D:/dophu_poem.docx\n",
      "Đang tải nội dung trang web: https://www.thivien.net/%C4%90%E1%BB%97-Ph%E1%BB%A7/Nguy%E1%BB%87t-d%E1%BA%A1/poem-T7ykhmCIqNvTZ_L2JmhFFw\n",
      "Tiêu đề: Bài thơ: Nguyệt dạ - 月夜 (Đỗ Phủ - 杜甫)\n",
      "Đã xảy ra lỗi: [Errno 13] Permission denied: 'D:/dophu_poem.docx'\n",
      "Đang tải nội dung trang web: https://www.thivien.net/%C4%90%E1%BB%97-Ph%E1%BB%A7/Mao-%E1%BB%91c-v%E1%BB%8B-thu-phong-s%E1%BB%9F-ph%C3%A1-ca/poem-j4UAOMEqMgeNDayunsRjYA\n",
      "Tiêu đề: Bài thơ: Mao ốc vị thu phong sở phá ca - 茅屋為秋風所破歌 (Đỗ Phủ - 杜甫)\n",
      "Đã thêm dữ liệu mới vào file D:/dophu_poem.docx\n",
      "Đang tải nội dung trang web: https://www.thivien.net/%C4%90%E1%BB%97-Ph%E1%BB%A7/Xu%C3%A2n-v%E1%BB%8Dng/poem-D1C_2BVK7I--Zczc0EEJ-A\n",
      "Tiêu đề: Bài thơ: Xuân vọng - 春望 (Đỗ Phủ - 杜甫)\n",
      "Đã thêm dữ liệu mới vào file D:/dophu_poem.docx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Đọc file csv chứa các URL\n",
    "df = pd.read_csv(\"D:/Dophu-url-poem2.csv\")\n",
    "\n",
    "# Hàm để thêm phần đầu của URL\n",
    "def add_prefix(url):\n",
    "    return \"https://www.thivien.net\" + url\n",
    "\n",
    "# Thêm phần đầu vào từng URL\n",
    "df['Full_URL'] = df['URL'].apply(add_prefix)\n",
    "\n",
    "# Hàm để trích xuất dữ liệu từ URL và lưu vào file .docx\n",
    "def extract_poem_data(url):\n",
    "    user_agents_list = [\n",
    "        'Mozilla/5.0 (iPad; CPU OS 12_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Mobile/15E148',\n",
    "        'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.83 Safari/537.36',\n",
    "        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/99.0.4844.51 Safari/537.36'\n",
    "    ]\n",
    "    HEADERS = {'User-Agent': 'Mozilla/5.0 (iPad; CPU OS 12_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Mobile/15E148'}\n",
    "    try:\n",
    "        # Delay 15 giây trước khi tải nội dung trang web\n",
    "        time.sleep(10)\n",
    "        \n",
    "        # Tải nội dung của trang web\n",
    "        print(\"Đang tải nội dung trang web:\", url)\n",
    "        #response = requests.get(url, headers={'User-Agent': random.choice(user_agents_list)})\n",
    "        response = requests.get(url, headers=HEADERS)\n",
    "        response.raise_for_status()  # Ném ngoại lệ cho các mã trạng thái không tốt\n",
    "   \n",
    "        # Tạo biến đếm cho số lần đã mở link\n",
    "        link_count = 0\n",
    "        \n",
    "        # Phân tích HTML content\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "        # Trích xuất tiêu đề\n",
    "        title = soup.title.text.strip()\n",
    "        print(\"Tiêu đề:\", title)\n",
    "\n",
    "        # Trích xuất phần văn bản chữ Hán và chữ Việt\n",
    "        han_viet_text = \"\"\n",
    "        for p_tag in soup.find_all('p', class_='HanChinese transcriptable'):\n",
    "            han_viet_text += p_tag.text.strip() + \"\\n\"\n",
    "\n",
    "        # Tìm thẻ meta có nội dung mô tả và lấy nội dung của nó\n",
    "        meta_description = soup.find(\"meta\", {\"name\": \"description\"})\n",
    "        if meta_description:\n",
    "            description_content = meta_description[\"content\"].strip()\n",
    "        else:\n",
    "            description_content = \"Không tìm thấy thẻ meta mô tả\"\n",
    "            \n",
    "        # Tìm tất cả các thẻ span có class là \"gray\"\n",
    "        gray_spans = soup.find_all(\"span\", class_=\"gray\")\n",
    "\n",
    "        # Lưu nội dung của từng thẻ span gray vào một list\n",
    "        translations = []\n",
    "        for gray_span in gray_spans:\n",
    "            em_tag = gray_span.find(\"em\")\n",
    "            if em_tag:\n",
    "                content_text = em_tag.text.strip()\n",
    "                translations.append(content_text)\n",
    "        \n",
    "        # Lưu dữ liệu vào file .docx\n",
    "        \n",
    "        doc = Document()\n",
    "        doc.add_heading(title, level=1)\n",
    "                \n",
    "        doc.add_paragraph(\"Chữ Hán:\")\n",
    "        han_viet_paragraph = doc.add_paragraph(han_viet_text)\n",
    "  \n",
    "                \n",
    "        doc.add_paragraph(\"Phiên âm:\")\n",
    "        doc.add_paragraph(description_content)\n",
    "                \n",
    "        doc.add_paragraph(\"Phiên dịch:\")\n",
    "        for translation in translations:\n",
    "            doc.add_paragraph(translation)\n",
    "                \n",
    "        doc.save(\"D:/dophu_poem.docx\")\n",
    "        print(\"Đã thêm dữ liệu mới vào file D:/dophu_poem.docx\")\n",
    "        # Tăng biến đếm sau mỗi lần mở link\n",
    "        link_count += 1\n",
    "        \n",
    "        # Kiểm tra nếu biến đếm chia hết cho 5 thì nghỉ ngơi 10 giây\n",
    "        if link_count % 5 == 0:\n",
    "            print(\"Nghỉ ngơi 10 giây...\")\n",
    "            time.sleep(15)\n",
    "            \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(\"Lỗi khi tải URL:\", e)\n",
    "    except Exception as e:\n",
    "        print(\"Đã xảy ra lỗi:\", e)\n",
    "\n",
    "# Gọi hàm để trích xuất dữ liệu từ từng URL và lưu vào file .docx\n",
    "for url in df['Full_URL']:\n",
    "    extract_poem_data(url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd68701b-9e56-4117-9e05-e51573f2d81f",
   "metadata": {},
   "source": [
    "# Phần Test khi chỉ lấy 1 bài thơ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b36135b7-6334-4187-a8bc-07f5d5e8469d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiêu đề: Bài thơ: Đối vũ thư hoài, tẩu yêu Hứa thập nhất bạ công - 對雨書懷走邀許十一簿公 (Đỗ Phủ - 杜甫)\n",
      "Nội dung mô tả:\n",
      "Đông nhạc vân phong khởi,\n",
      "Dung dung mãn thái hư.\n",
      "Chấn lôi phiên mạc yến,\n",
      "Sậu vũ lạc hà ngư.\n",
      "Toạ đối hiền nhân tửu,\n",
      "Môn thinh trưởng giả xa.\n",
      "Tương yêu quý nê ninh,\n",
      "Kỵ mã đáo giai trừ.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "HEADERS = {'User-Agent': 'Mozilla/5.0 (iPad; CPU OS 12_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Mobile/15E148'}\n",
    "\n",
    "# URL của trang web cần lấy nội dung\n",
    "url = \"https://www.thivien.net/%C4%90%E1%BB%97-Ph%E1%BB%A7/%C4%90%E1%BB%91i-v%C5%A9-th%C6%B0-ho%C3%A0i-t%E1%BA%A9u-y%C3%AAu-H%E1%BB%A9a-th%E1%BA%ADp-nh%E1%BA%A5t-b%E1%BA%A1-c%C3%B4ng/poem-94BVxupMVXN25dDk5qXS2g\"\n",
    "\n",
    "try:\n",
    "    # Tải nội dung của trang web\n",
    "    response = requests.get(url, headers=HEADERS)\n",
    "    response.raise_for_status()  # Ném ngoại lệ cho các mã trạng thái không tốt\n",
    "\n",
    "    # Phân tích HTML content\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # Trích xuất tiêu đề\n",
    "    title = soup.title.text.strip()\n",
    "    print(\"Tiêu đề:\", title)\n",
    "\n",
    "    # Tìm thẻ meta có nội dung mô tả và lấy nội dung của nó\n",
    "    meta_description = soup.find(\"meta\", {\"name\": \"description\"})\n",
    "    if meta_description:\n",
    "        description_content = meta_description[\"content\"].strip()\n",
    "        print(\"Nội dung mô tả:\")\n",
    "        print(description_content)\n",
    "    else:\n",
    "        print(\"Không tìm thấy thẻ meta mô tả\")\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(\"Lỗi khi tải URL:\", e)\n",
    "except Exception as e:\n",
    "    print(\"Đã xảy ra lỗi:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee4ae6c-fc45-4ee4-b814-d9a3431b59cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
